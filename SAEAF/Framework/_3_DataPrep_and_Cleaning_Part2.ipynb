{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drop_columns: customerID\n"
     ]
    }
   ],
   "source": [
    "\"\"\" All modules for this steps of the pipeline are defined here. \"\"\"\n",
    "\n",
    "from _2_FeatureEngineeringAndSelection import run_feature_select\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Loading environment variables from .env file\"\"\"\n",
    "load_dotenv()\n",
    "\n",
    "split_option = os.getenv(\"custom_split\")\n",
    "\n",
    "try:\n",
    "    train_ratio = float(os.getenv(\"training_split\"))\n",
    "    val_ratio = float(os.getenv(\"validation_split\"))\n",
    "    test_ratio = float(os.getenv(\"testing_split\"))\n",
    "except (TypeError, ValueError):\n",
    "    raise ValueError(\"Custom split ratios must be valid numbers in the .env file.\")\n",
    "\n",
    "balance_option = os.getenv(\"balance_option\")\n",
    "target_column = os.getenv(\"target_column\")\n",
    "\n",
    "train_path = os.getenv(\"train_path\")\n",
    "test_path = os.getenv(\"test_path\")\n",
    "validation_path = os.getenv(\"validation_path\")\n",
    "base_path = os.getenv(\"base_path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Function to split data into training, validation, and testing sets based on defined ratios. \"\"\"\n",
    "\n",
    "def split_data(df):\n",
    "    \n",
    "    if split_option not in [\"0\", \"1\"]:\n",
    "        raise ValueError(\"Invalid value for 'custom_split' in .env file. Use '0' or '1'.\")\n",
    "\n",
    "    if split_option == \"0\":\n",
    "        print(\"------------------------\")\n",
    "        print(\"User chose default split\")\n",
    "        print(\"------------------------\")\n",
    "        # Default split: 70% train, 20% validation, 10% test\n",
    "        train_df, temp_df = train_test_split(df, test_size=0.3, random_state=42)\n",
    "        val_df, test_df = train_test_split(temp_df, test_size=1/3, random_state=42)\n",
    "    else:\n",
    "        print(\"-------------------------------------------------------------------------------------------------------------\")\n",
    "        print(f\"User custom split default split with Training: {train_ratio}; Testing: {test_ratio}; Validation: {val_ratio}\")\n",
    "        print(\"-------------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "        total = train_ratio + val_ratio + test_ratio\n",
    "        \n",
    "        if not abs(total - 1.0) < 1e-6:\n",
    "            raise ValueError(\"Custom split ratios must sum to 1.0\")\n",
    "\n",
    "        # First split: train and temp\n",
    "        train_df, temp_df = train_test_split(df, test_size=(1 - train_ratio), random_state=42)\n",
    "\n",
    "        # Calculate proportions for validation and test from the remaining data\n",
    "        val_proportion = val_ratio / (val_ratio + test_ratio)\n",
    "        val_df, test_df = train_test_split(temp_df, test_size=(1 - val_proportion), random_state=42)\n",
    "\n",
    "    return train_df, val_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Function to balance the training data based on user-defined method. \"\"\"\n",
    "\n",
    "def balance_data():\n",
    "\n",
    "    if not train_path or not target_column or not balance_option:\n",
    "        raise ValueError(\"Missing required .env variables: input_data_path, target_column, or balance_option.\")\n",
    "\n",
    "    df = pd.read_csv(train_path)\n",
    "\n",
    "    if balance_option not in [\"1\", \"2\", \"3\", \"4\", \"5\"]:\n",
    "        raise ValueError(\"Invalid value for 'balance_option' in .env file. Use 1â€“5.\")\n",
    "\n",
    "    if balance_option == \"1\":\n",
    "        print(\"-----------------------\")\n",
    "        print(\"User chose no Balancing\")\n",
    "        print(\"-----------------------\")\n",
    "        balanced_df = df  # No balancing\n",
    "\n",
    "    else:\n",
    "        X = df.drop(columns=[target_column])\n",
    "        y = df[target_column]\n",
    "\n",
    "        if balance_option == \"2\":\n",
    "            print(\"---------------------------------------\")\n",
    "            print(\"User chose Undersampling majority class\")\n",
    "            print(\"---------------------------------------\")\n",
    "\n",
    "            # Undersample majority class\n",
    "            df_majority = df[df[target_column] == y.value_counts().idxmax()]\n",
    "            df_minority = df[df[target_column] == y.value_counts().idxmin()]\n",
    "            df_majority_downsampled = resample(df_majority,\n",
    "                                               replace=False,\n",
    "                                               n_samples=len(df_minority),\n",
    "                                               random_state=42)\n",
    "            balanced_df = pd.concat([df_majority_downsampled, df_minority])\n",
    "            balanced_df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "        elif balance_option == \"3\":\n",
    "            print(\"------------------------------\")\n",
    "            print(\"User chose SMOTE oversampling\")\n",
    "            print(\"------------------------------\")\n",
    "            # SMOTE oversampling\n",
    "            smote = SMOTE(random_state=42)\n",
    "            X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "            balanced_df = pd.concat([pd.DataFrame(X_resampled, columns=X.columns), pd.Series(y_resampled, name=target_column)], axis=1)\n",
    "\n",
    "        elif balance_option == \"4\":\n",
    "            print(\"------------------------------\")\n",
    "            print(\"User chose Stratified sampling\")\n",
    "            print(\"------------------------------\")\n",
    "            # Stratified sampling (equal number of samples from each class)\n",
    "            min_class_size = y.value_counts().min()\n",
    "            dfs = [df[df[target_column] == label].sample(n=min_class_size, random_state=42) for label in y.unique()]\n",
    "            balanced_df = pd.concat(dfs).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "        elif balance_option == \"5\":\n",
    "            # Random oversampling\n",
    "            ros = RandomOverSampler(random_state=42)\n",
    "            X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "            balanced_df = pd.concat([pd.DataFrame(X_resampled, columns=X.columns), pd.Series(y_resampled, name=target_column)], axis=1)\n",
    "\n",
    "    # Save to train_data.csv\n",
    "    balanced_df.to_csv(train_path, index=False)\n",
    "    print(f\"Balanced training data saved to {train_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split and saved all datasets successfully.\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Function to split features and target variable into separate CSV files for train, validation, and test datasets.\"\"\"\n",
    "\n",
    "def SplitXandY(train_path, validation_path, test_path, target_column):\n",
    "    # Read the datasets\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    validation_df = pd.read_csv(validation_path)\n",
    "    test_df = pd.read_csv(test_path)\n",
    "\n",
    "    # Split train\n",
    "    X_Train = train_df.drop(columns=[target_column])\n",
    "    Y_Train = train_df[[target_column]]\n",
    "\n",
    "    # Split validation\n",
    "    X_Val = validation_df.drop(columns=[target_column])\n",
    "    Y_Val = validation_df[[target_column]]\n",
    "\n",
    "    # Split test\n",
    "    X_Test = test_df.drop(columns=[target_column])\n",
    "    Y_Test = test_df[[target_column]]\n",
    "\n",
    "    # Write to CSV files\n",
    "    X_Train.to_csv(f\"{base_path}X_Train.csv\", index=False)\n",
    "    Y_Train.to_csv(f\"{base_path}Y_Train.csv\", index=False)\n",
    "    X_Val.to_csv(f\"{base_path}X_Val.csv\", index=False)\n",
    "    Y_Val.to_csv(f\"{base_path}Y_Val.csv\", index=False)\n",
    "    X_Test.to_csv(f\"{base_path}X_Test.csv\", index=False)\n",
    "    Y_Test.to_csv(f\"{base_path}Y_Test.csv\", index=False)\n",
    "\n",
    "    print(\"Split and saved all datasets successfully.\")\n",
    "\n",
    "SplitXandY(train_path, validation_path, test_path, target_column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"  Main function to run feature engineering and selection. \"\"\"\n",
    "\n",
    "def run_data_prep_part2():\n",
    "    \n",
    "    dataFrame = run_feature_select()\n",
    "\n",
    "    print(\"##################################\")\n",
    "    print(\"Running data preparation part 2...\")\n",
    "    print(\"##################################\")\n",
    "\n",
    "    train_df, val_df, test_df = split_data(dataFrame)\n",
    "\n",
    "    # Save the validation and test split dataframes to CSV files\n",
    "    train_df.to_csv(train_path, index=False)\n",
    "    val_df.to_csv(validation_path, index=False)\n",
    "    test_df.to_csv(test_path, index=False)\n",
    "\n",
    "    balance_data()\n",
    "    SplitXandY(train_path, validation_path, test_path, target_column)\n",
    "    \n",
    "    print(\"Data preparation part 2 completed.\")\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    run_data_prep_part2()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Masters",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
